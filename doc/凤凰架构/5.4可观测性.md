日志：
    日志的职责是记录离散的时间，从中分析程序的行为，打印日志是程序中最简单的工作之一，
    但收集和分析很复杂面对庞大的日志，分析日志最优实践性的“大数据形同”
追踪
    在单体应用追踪局限于栈追踪，但在微服务时代跨越多个服务，分布式系统成为“全链路追踪”
    主要是排查调用链的那一部分，那个方法错误或阻塞，输入输出是否与其等
度量
    度量是对系统中某一类信息统计聚合，度量的目的是监控和预警。


日志的收集与分析大多统一到ELK技术栈中
度量方面跟随着kubernetes统一容器编排，Prometheus也击败了其他前辈。成为云原生监控的标准。


追踪与具体的网络协议，程序语言密切相关。
    各个服务是用http还是grpc通信会直接影响到追踪的实现。不同语言也会影响进程内调用栈的追踪方式。这是有较强的侵入性。
    这也决定了追踪无法一家独大的情况。目前有skyWalking，Zipkin,Jaeger这些优秀产品
收集日志不必关系日志是java还是golang输出。
度量也相同是根据已有数据进行汇总及处理


日志
    输出
        就如流水账一样，无可遗漏的记录，格式统一，内容恰当，
        避免：
            1.避免打印敏感数据（密码，账号，身份证这些建议用id来替换）
            2.避免引用慢操作（打印日志本来就是从上下文获取的，如果上下文本来就没这个数据，专门去调用数据库或远程服务器或大量计算才能获取）
            3.避免打印追踪诊断信息（不要打印调试信息）
        提倡：
            1.处理请求的traceID(贯穿整个链，如果响应异常可通过该ID快速找到日志及问题)
            2.系统运行时的关键信息（原则上只要程序发生的事件都是有价值的）
            3.启动时配置信息（对系统启动或配置变更时的更新信息）
       
    收集及缓冲
        写日志是服务节点进行的，在分布式系统中一个请求跨越多个节点，为了能看到全部日志，需要覆盖整个链路的全局日志系统（日志收集器）。
        收集器不仅要覆盖所有数据，而且还要保证数据的连续性，日志收集器部署实例达到百万量级别，日志系统不追求绝对完整精确，只追求在代价可承当的范围内尽可能保证较高的数据质量
        缓解压力的做法就是将日志接受者从Logstash和Elasticsearch转移到抗压能力更高的队列缓存，可在Logstash之前加一个kafka或redis作为缓冲层面对突发流量进行削峰填谷，

        ELK:
            Logstash:
                ELK日志收集及加工的职责都是由Logstash承担，除了部署在各个节点中收集外，还同时设有独立的部署接地那，扮演转换日志的服务（master）角色。

                它拥有良好的插件设置，收集，装换，输出都支持插件化的定制，默认堆大小是1GB，但每个节点部署的日志收集器显得有点太负重，
                    后来将所有需要在服务节点中处理的工作整理以Libbeat为核心的Beats框架，并使用Golang重写一个功能较少，更轻量级的日志收集器器,Filebeats。

            Beats家族:
                除了Filebeats外，还有以下功能，以至于ELK可以一定程度上替代度量和追踪系统，在小心分布式系统时便利的，但大型系统还是建议使用专业工具
                    1.用于收集Linux审计数据的Auditbeat
                    2.用于无服务计算架构的Functionbeat
                    3.用于心跳检测的Heartbeat
                    4.用于聚合度量的Metricbeat
                    5.用于收集 Linux Systemd Journald 日志的Journalbeat
                    6.用于收集 Windows 事件日志的Winlogbeat
                    7.用于网络包嗅探的Packetbeat，等等


        加工和聚合
            存到Elasticsearch之前，一般需要加工转换和聚合处理，因为日志是非结构化数据，一行日志可能包含很多项信息，如果不做处理，不利于系统对比，过滤条件。
            Logstash的职责把日志中非结构化的荣光Grok语法转换结构化数据，可以调用插件来完成时间出来，类型转换，归类等工作，以json方式输出到Elasticsearch

            通过Elasticsearch本身的处理能力做实时的聚合统计，这很便捷，不过要消耗 Elasticsearch 服务器的运算资源。(用于一些未知的需求)
            另一种解决方案是在收集日志后自动生成某些常用的、固定的聚合指标，这种聚合就会在Logstash中通过聚合插件来完成。(用于一些已经确立的统计)
            这两种聚合方式都有不少实际应用，前者一般用于应对即席查询，后者用于应对固定查询。

        存储和查询
            Elasticsearch是整个 Elastic Stack 技术栈的核心,filebeat、Logstash、Kibana 都有替代品，有自由选择的余地，
            唯独Elasticsearch在日志分析这方面完全没有什么值得一提的竞争者，几乎就是解决此问题的唯一答案，优势如下：
                1.从数据特征的角度：日志是典型的时间流数据，日志虽增长很快，但写入数据基本没有再发生变动的可能，决定了可以通过时间为索引，
                    避免动态创建寻找节点，创建分片，在集群中广播变动信息等开销，
                2.从数据价值的角度：随着时间的推移，早期数据的价值逐渐失去，这就能决定了冷热数据，采用不同的硬件策略，进行归档
                3.从数据使用的角度：分析日志依赖全文检索和即席查询，实时性的要求是处于实时与离线两者之间的——“近实时”，不要求马上能查到，但不接收太久后才同步。

            kabana 
                它视为Elasticsearch的GUI,把数据进行检索，聚合，统计，定制各种图形，表格，指标，统计。
                

-------------
链路追踪
    广义上讲，一个完整的分布式追踪系统应该由数据收集、数据存储和数据展示三个相对独立的子系统构成，
    狭义上,讲的追踪则就只是特指链路追踪数据的收集部分


    追踪与跨度
        从客户端发起请求到抵达系统的边界开始，记录请求流经每一个服务，直到向客户端响应为止，这个那个过程称为一次“追踪”
            由于每次追踪调用数量不定，坐标不定的多个服务，为了记录具体调用哪些服务，以调用顺序，开始/结束时间，统计时长等信息，在调用前都有一个调用记录
            我们称这个记录为跨度（span），span的结构非常简单，以便于放在日志或网络协议头里面。通过有序有层级的span组成一个“追踪树”
                1.起始时间戳，起止时间
                2.traceId
                3.当前span的id，父span的id等

        目标：目的是为了排查故障及分析性能提供支持，提供持续的请求处理响应，同时持续生成trace,按照次序中的每一个span记录调用关系，
        从span的时间信息及响应结果，就能定位缓慢或出错的服务。将trace与历史记录进行对比，就能分析服务西能，定位优化目标

        实现：每次服务调用记录trace和span，但在实际中需要考虑服务的异构性，服务的交互采用不同的网络协议，每一种兼容，都会增加实现的工作量。
            非功能性的挑战源于四个方面
            1.低性能损耗（不能对性能有负担）
            2.对应用透明（对开发人员是透明化的）
            3.随应用扩展（当业务扩展时，追踪系统也自动扩展，无需运维人员）
            4.持续监控（7*24的工作，否则难以定位抖动行为）

        
    数据收集
        有主流的实现方案：
        1基于日志：
            输出到应用日志，随着所有节点的日志归集一起再从全局日志反推出完整调用拓扑关系，对应用只是少量侵入，对性能影响低
            
            缺点：就是日志不追求绝对的连续与一致，不及其他两种精准。业务服务的调用与日志的并归并不是同时完成，通常不是同一个进程，有可能业务已经结束了但日志归并不及时或精度丢失，导致日志出现延迟或缺失。对中小型应用有一定的便利性
        2基于服务 
            通过某些手段给目标应用注入追踪探针，他一般有自己的服务注册，心跳检查等功能，有专门的收据收集协议，从目标系统中监控得到服务调用的信息，
            通过另一次独立的http或RPC请求发送给追踪系统。因此会消耗更多的资源，也有较强的侵入性，换来的是精准性及稳定性
        3基于边车代理
            服务网关的方案，实现分布式追踪模型，对应用透明，无论是日志还是服务本身都不会有任务变化，不依靠编程语言，他只是通过http或RPC来访问服务就可以追踪到
            他有独立的数据通道，避免对程序的干扰，是最佳准确性，但网络服务还不普及，他只能实现服务调用层面的追踪，本地调用级别是做不到的


-------------
集合度量
    度量总体分为客户端的指标收集，服务的存储查询已经终端的监控预警三个独立的过程，每个过程在系统中也有设置对应的组件实现，
    Prometheus在度量领域的统治力虽然还暂时不如日志领域中 Elastic Stack 的统治地位那么稳固，但在云原生时代里，基本也已经能算是事实标准了。

        指标收集
            面向指标的数据类：
            计数度量器：PV、UV，营业额等等
            瞬态度量器：在某个时间当前的某个指标的数值，
            吞吐率度量器：TPS,QPS等（每秒某个操作的执行次数）
            直方图度量器：GDP等（有x，y表现为随着x的变化，y的不同值）
            采样点度量器：分位图是统计学中通过比较各分位数的分布情况的工具，用于验证实际值与理论值的差距，评估理论值与实际值之间的拟合度

            获取方式：
            拉取式采集：pull 主动向目标系统拉取
            推送式采集：push 由目标系统主动推送

        存储查询
            建设度量系统，肯定不能让度量反倒成了业务系统的负担（不能使用传统的sql，需要通过NoSQL,他具有不可更改性及时间有序性），可见，度量的存储是需要专门研究解决的问题。
            业界早就已经存在了专门针对该类型数据的数据库了，即“时序数据库”（产生速度快，依赖采集时间，具有不变性，唯一性，有序性）

        监控预警
            指标度量是手段，最终目的是做分析和预警。但对于度量系统本身而言，他们相对是外围功能，
            度量系统广义上：
                面向目标系统进行指标采集的客户端，负责调度、存储
                提供查询能力的服务端
                面向最终用户的终端组成。
            度量系统狭义上：
                包括客户端和服务端，不包含终端。

            良好的可视化能力提高度量系统的产品里，长期趋势分析，故障分析，即需要度量指标的持续收集，统计，往往还需要数据可视化，从中更容易挖掘规律
            度量信息的另一种主要的消费途径是用来做预警。譬如你希望当磁盘消耗超过 90%时给你发送一封邮件或者是一条微信消息，通知管理员过来处理，这就是一种预警。