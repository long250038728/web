透明 && 多级分流
1.引导流量分配到最合适的系统部件中进行响应
2.透明的方式（平时无感知，基础架构/底层已经帮我们实现了导致了现在我们很少去关注他）
3.避免把流量全部的压在了单点设施上（数据库等）


客户端： 客户端缓存  =》 http缓存  =》
中间层：                         CDN =》 负载均衡  =》 网关  =》 服务集群中某台服务器 =》 
服务器：                                                                        数据校验 =》 服务器缓存 =》 数据库

1.先让一些机制减少对服务器的请求 （客户端缓存 、http缓存）
2.实在没办法需要请求则把一些压力请求在其他地方先分担 （CDN、负载均衡、网关、服务器集群） 
3.到达了某台服务器后看能不能先不直接命中到单体服务/数据库（数据校验，缓存，NoSQL,kafka消息队列）

中间层往往会忽略他们的存在：
    1.CDN：    根据ip选择就近CDN节点，把静态数据放到其他地方，
    2.负载均衡：根据ip选择就近网关
    3.网关：    可以根据轮训算法调整到不同的服务器集群中的某台服务器



在用户使用系统的过程中会进过一系列设施。我们应该意识到不同设施在系统中的不同价值。
    1.经过网关（入口负载均衡）
    2.负载均衡（应用负载均衡——服务注册/发现）
    3.缓存
    4.服务器集群
    5.数据库

    有一些部位位于客户达或网络边缘，避免给后端io与cpu代理压力
        如本地缓存，内容分发网络CDN，方向代理
    有一些部位能够线性扩展，易与伸缩，可使用较小代价堆叠机器来获取并发性能
        如集群
    有一些部位是系统的稳定性受影响，要时刻保持容错备份
        如配置中心，注册中心
    有一些部位是天生单点
        如路由，网关或负载均衡，关系型数据库

    1.应尽可能减少单点部件，如只能单点应最大限制减少到达的流量
    2.奥卡姆发展，对分流手段充分理解及准备，应意识到不是越多越好，必要的时候再去考虑部署他们。

----------

##缓存
    http强制缓存：
        状态缓存是不经过服务器的，客户端直接根据缓存信息对目标网站的状态判断。譬如在响应的10分钟内，资源的内容和状态一定不会被改变。因此客户端无需经过任何请求，在该时间一直持有和使用本地缓存的副本。

        在浏览器地址输入、页面跳转、新开窗口，前进和后退均可生效，但在用户主动刷新应当失效。
            1.expires 在http协议头中跟随一个时间参数。当服务器返回带有该信息意味直接缓存，无需再重新发送请求
                1.受到客户端本地时间的约束(有可能本地时间比较快或慢)
                2.无法处理用户身份的隐私资源（如代理服务器或内容分发网络缓存起来，则其他未认证的用户被获取）
                3.无法描述“不缓存”的语义，浏览器为了提升性能，往往会在每次会话中缓存某些mime资源，http1.0的无服务器就缺乏手段强制浏览器不允许缓存某个资源。
            2.cache-control 是http1.1协议中定义的强制缓存header，他比expries丰富很多，
                max-age和s-maxage：max-age后面跟随秒为单位的数字。避免本地时间的问题，s-maxage即允许cdn，代理等持有的缓存有效时间，
                public和private：指明是否涉及用户身份的私有资源
                no-cache和no-store：no-cache不被缓存，no-store不强制会话中相同的url资源重复获取
                no-transform：禁止资源被任何时候修改
                min-fresh和only-if-cached：min-fresh以秒为单位，建议服务器能返回不是少于该时间的缓存资源。only-if-cached表示客户端要求不必给他发送资源的具体内容
                must-revalidate和proxy-revalidate：must-revalidate 表示在资源过期后，一定需要从服务器中进行获取，即超过了 max-age 的时间后，就等同于 no-cache 的行为，proxy-revalidate 用于提示代理、CDN 等设备资源过期后的缓存行为，除对象不同外，语义与 must-revalidate 完全一致。

    http协商缓存：
        强制缓存基于时效性，无论是人还是服务器，大多情况都无法保证多久不会改变。协商缓存是基于变化检测的机制，在一致性上会更好的表现，单一次检测的交互开销，性能会差一点。
            当强制缓存存在时，直接从强制缓存中返回资源，无需进行变动检查，当强制缓存超时或被禁止时，协商缓存可以正常工作
                变动检查机制：
                    1.根据资源的修改时间进行检查
                    2.根据资源唯一标识是否发生改变
                    Last-Modified 和 If-Modified-Since：Last-Modified 是服务器的响应 Header，用于告诉客户端这个资源的最后修改时间。对于带有这个 Header 的资源，当客户端需要再次请求时，会通过 If-Modified-Since 把之前收到的资源最后修改时间发送回服务端。
                    Etag 和 If-None-Match：Etag 是服务器的响应 Header，用于告诉客户端这个资源的唯一标识。HTTP 服务器可以根据自己的意愿来选择如何生成这个标识，譬如 Apache 服务器的 Etag 值默认是对文件的索引节点（INode），大小和最后修改时间进行哈希计算后得到的。对于带有这个 Header 的资源，当客户端需要再次请求时，会通过 If-None-Match 把之前收到的资源唯一标识发送回服务端。

    客户端本地缓存
        1.更加灵活
        2.更加可控


----------

##域名解析DNS:
    1.客户端检查本地dns缓存（通过TTL超期后重新获取保证一致性）
    2.客户端将地址发送给本机操作系统中的本地dns，这个本地dns是有用户手工设置，也可通过dhcp分配时从ppp服务器获取
    3.去互联网查找：通过递归的方式查找
        权威域名服务器，特定域名的dns服务器。
        根域名服务器。他可以默认为他们内置操作系统代码中，全世界有13组跟域名服务器。
        
        1.看看本地有没有权威域名服务器地址，有则获取，没有则查找并记录
        2.看看本地有么有根域名服务器地址，有则获取，没有则查找并记录
        3.从有根域名进行查找对应的服务器ip

    缺点：
        1.响应速度，在极端条件下服务器无缓存需每个域名层级获取查找结果。
        2.dns分层意味每一层都可能受到中间人攻击。

        
    前端优化手段
        解决1.通过link连接，让浏览器提前对域名进行解释 “<link rel="dns-prefetch" href="xxxxxx.com">”
        解决2：通过HTTP DNS 将原来的dns解析开放为一个基于https请求协议的查询服务。替代udp传输协议。(应用层处理)

----------

##传输链路
    经过dns服务的解析指引，程序发出的请求流量正式离开客户端，踏上了服务器为目的地的旅途。
        很多人认为传输链路是开发者不可控的，网络路由跳点的数量，运营商铺设路线的之类，带宽的大小，速率的高度，
        但是事实并非如此，程序发出的请求能否与应用层，传输层协议提倡的方式相匹配，对传输效率有极大影响

        连接数量优化
            http的主要特征是数量多（html，js，cs，图片音频）、时间短、资源小、切换快。
            tcp必须经过三次握手，主要特征是稳定性和可靠性
            我们知道http3之前是以tcp为传输层的应用协议，但http over tcp 这种搭配只能说是tcp在当前网络统治性的地位所造成的结果，而不是他们配合是合适的。

            1.大量短而小的 TCP 连接导致了网络性能的瓶颈。为了缓解 HTTP 与 TCP 之间的矛盾，聪明的程序员们一面致力于减少发出的请求数量
            2.持久连接（Persistent Connection），也称为连接Keep-Alive 机制。
                让客户端对同一个域名长期持有一个或多个不会用完即断的 TCP 连接。
                典型做法是在客户端维护一个 FIFO 队列，每次取完数据之后不自动断开连接，获取下一个资源时可直接复用，避免创建TCP连接的成本。
                缺点：
                    “队首阻塞”（Head-of-Line Blocking）入列顺序只能按照浏览器遇见这些资源的先后顺序来决定的，如果资源中有让服务器陷入长时间运算状态导致后面阻塞等待。（顺序乱了，客户端就很难区分哪个数据包归属哪个资源了）

                “HTTP 管道”（HTTP Pipelining）复用技术（服务器中也建立类似客户端的 FIFO 队列）
                    让客户端一次将所有要请求的资源名单全部发给服务端，服务端能够较为准确地评估资源消耗情况。
                        进而能够更紧凑地安排资源传输，保证队列中两项工作之间尽量减少空隙

            在 HTTP/1.x 中，
                HTTP 请求就是传输过程中最小粒度的信息单位了，所以如果将多个请求切碎，再混杂在一块传输，客户端势必难以分辨重组出有效信息。
            在 HTTP/2 中，
                帧（Frame）才是最小粒度的信息单位，每个帧都附带一个流 ID 以标识这个帧属于哪个流。这样，在同一个 TCP 连接中传输的多个数据帧就可以根据流 ID 轻易区分出开来，在客户端毫不费力地将不同流中的数据重组出不同 HTTP 请求和响应报文来。称为 HTTP/2 多路复用（HTTP/2 Multiplexing）技术


    

        传输压缩
            http很早就支持Gzip压缩，传输数据量一般会降原来20%，在网络时代早期，服务器的处理能力还很弱，为了启动压缩，会把静态资源预先压缩存起来，当客户端支持接收压缩文件则传压缩文件，否则返回未压缩的原版。而现代web服务器处理大幅度提升，没人再用麻烦的预压缩方式。都是服务器对符合条件的请求输出进行“即时”压缩，压缩过程在内存流中处理，不必等到资源压缩完再返回。这个唯一不好的地方就是服务器再也没有办法给出content—length这个响应头。

            客户端就必须要有除了关闭连接外的机制来判断什么时候传递完成，在http1的时候判断content-length.由于启动压缩后无法给出content-length、在http1.1解决这个缺陷，增加“分块传输编码”的资源结束判断机制，
            在header加入“transfer-encoding chunked”之后，代表这个响应报文采用分块编码，此时报文中body需要改为一些了“分块”传输，每个分块包含十六进制的长度值和对应长度的数据内容。长度独占一行。从下一行开始，最后以一个长度为0的分块表示资源结束。


        快速udp网络连接
            http是应用协议不是传输协议，他的设计本比应该过多考虑传输细节。QUIC以udp为协议基础而udp没有丢包重传的腾讯，所以QUIC的可靠传输能力并不是由底层提供而是自己实现，好处在于可以对每个流能做单独的控制，如果一个流出错，协议栈仍然可以继续为其他流提供数据。在大多情况下，tcp协议到数据包丢失或损坏通知之前，可能收到大量的数据，在纠正错误之前，其他请求都会等待甚至重发，这也是http2未能解决传输大文件慢的问题。

            QUIC的另一个设计是面向移动端设备，以前tcp，udp传输在设计的时候没想到移动端今日如此盛行，当设备在不同的wifi切换，如果使用tcp协议，所有连接都会超时，断连，然后重新创建，这个过程带来很高延迟。为此提出了连接标识符的概念，可以表示客户端及服务器之间的连接，无需依靠ip地址，这样切换wifi只需要发送一个包含此表示的数据包，即可重用既有的连接。

            无论是tcp还是http已经存在数十年，他们积累大量用户的同时也承载很重的技术惯性，要http从tcp迁移走，不是一件容易的事，大量互联网基础设施中的中间设备，都是面向tcp协议去建造的，所以需要同时开启QUIC和tcp，如果quic连接失败时退回tcp连接，让用户无感知。




----------

##内容分发网络CDN:
    把内容分发到各个地方的服务器中，可通过就近的方式获取。能解决互联网系统跨运营商跨物理所导致的延迟问题，能为网站流量带宽起到分流和减负的作用。
        主流的内容分发方式（cdn主节点到cdn缓存节点）：
            1.主动分发：发起由源站主动发起，将内容推送到用户边缘的cdn上
            2.被动会员：由用户访问触发。当某个资源首次被客户请求时，cnd缓存节点上发现没有该资源，实时从源站获取。
        内容分发最初是为了静态资源设计的。后来进行了不断的实践扩展
            1.加速静态资源
            2.安全防护（可视为堡垒机，恶意攻击者不那么容易直接威胁到源站）
            3.协议升级（对接/出售ssl证书）
            4.修改资源 可以对源站未压缩的资源自动压缩并修改，节省用户带宽消耗
            5.访问控制 可以加入ip黑、白名单，
            6.注入功能，在cdn不修改源码的前提下，提供注入各种功能

----------

##负载均衡
    一般实际用于生产环境的，几乎离不开集群。信息系统不论是采用单体架构多副本或微服务架构，不论是为了高可用还是高性能。都需要多台集群来扩展能力，希望不管请求到那台机器，得到是相同的处理。构建和调度集群，有必须对用户保持透明，承当这个职责的组件

    负载均衡往往是多级的，比如各地建立多个机房，或机房有不同的网络链路入口的大型网络。
        从DNS开始，通过“域名”=>"cname"=>"负载调度服务"=》“就近的数据中心入口”的路径，通过ip分配到一个合适的数据中心，然后到各式各样的负载均衡。

    四层负载：性能高（ip/tcp）
        传输层，这些工作模式的共同特点是维护一个tcp连接，
    七层负载：功能强 (解析内容)
        应用层
    多级混合负载均衡：
        传输层 + 应用层


    数据链路层负载均衡(但它并不适用于所有的场合)
        传输的内容是数据帧（frame），譬如常见的以太网，ADSL宽带的ppp帧
        帧结构中注意的是“mac目标地址”跟“mac源地址”。我们每块网卡都有独立的mac地址，
            以太帧上这个两个地址是告诉交换机，此帧是从连接在交换机上的那个端口的网卡发出，送到那个网卡。
                修改请求的数据帧中的mac目标地址。让用户原本发送给负载均衡请求的数据帧，
                被二层交换机根据新的mac目标地址转发到对应的服务器网卡。

        转发过程中只修改帧的mac目标地址，不实际更新上层协议。所以对于其他层，数据是未改变，及ip数据包中包含的源和目标的ip地址，只有真实服务器保证自己的IP地址与数据包中的目标IP地址一致，这个数据包才能被正确处理。
        
        使用这种负载均衡模式时，需要把真实物理服务器集群所有机器的虚拟IP地址（Virtual IP Address，VIP）配置成与负载均衡器的虚拟 IP 一样，这样经均衡器转发后的数据包就能在真实服务器中顺利地使用。也正是因为实际处理请求的真实物理服务器 IP 和数据请求中的目的 IP 是一致的，所以响应结果就不再需要通过负载均衡服务器进行地址交换，可将响应结果的数据包直接从真实服务器返回给用户的客户端，避免负载均衡器网卡带宽成为瓶颈，因此数据链路层的负载均衡效率是相当高的。


    网络层负载均衡
        传输的单位是分组包。以ip为例，一个ip数据包由headers和payload两部分，在网络层中只要知道ip分组数据包的headers带有源ip和目标ip即可，沿用第二层修改mac相似，通过改变ip地址来实现数据包的转发

            1.保持原数据包不变，新增一个数据包，把这个发到真实服务器后，把由负载均衡器自动添加的那层 Headers 扔掉，还原出原来的数据包来进行使用。这样，真实服务器就同样拿到了一个原本不是发给它（目标 IP 不是它）的数据包，达到了流量转发的目的（需要真实服务器支持“IP隧道协议”，需要保证所有的真实服务器与均衡器有相同的虚拟ip）
            
            2.nat方式，在转发时，不仅修改目标ip地址，连源ip都一起修改，原地址改为自己的ip，这样的好处就是无需配置网关就能共正常的回到负载均上，做到彻底透明（无法拿到正式的服务器ip）

    应用层负载均衡
        四层负载均衡的工作模式是“转发”，直接通过tcp报文底层的数据格式转发到真实服务器上，此时客户端响应请求的真实服务器维持着同一条tcp连接。工作在第四层之后无法再进行转发，只能通过代理。此时真实的服务器，负载均衡，客户端三者由两条tcp通讯维护。

        从性能上比不过四层负载均衡，他比四层至少多了一轮tcp握手，有着跟nat转发一样带宽的问题，消耗更多cpu，但如果网站的瓶颈不是网络性能，要论整个服务集群对外所体现出来的性能，七层负载均衡就有他的用武之地，英文他可以感知应用层通信的具体内容。往往能做出更明智的决策。玩出更多花样。

        四层负载就像自助排号机，效率高且不疲惫，根据排号机选择对应的窗口接口，
        七层负载就像大堂经理，了解业务，安排排号，理财，取款等业务，根据内部资源获得同意协调处理，加快客户业务办理流程。一些无需柜台办理的业务，大堂经理直接解决就可以。
            实现静态资源缓存的请求直接在方向代理直接返回，无需到真实服务器。

        1.cdn应用，做的就是七层负载器就可以实现
        2.七层更智能的路由。
        3.某些安全可以由七层来抵御。如ddos攻击，在技术层面四层无法感知
        4.在微服务中，链路治理需要七层（降级，熔断，异常注入等）


    均衡策略
        1.轮训策略
        2.权重轮训策略
        3.随机策略
        4.权重随机策略
        5.一致性hash
        6.响应速度均衡
        7.最少连接数均衡

    软件负载均衡
        操作系统内核：LVS
        应用程序：nginx，haProxy，keepAlived
    硬件负载均衡
        专用集成电路。专有处理芯片支持，避免操作系统层面的损耗。


----------

##服务器缓存
    缓存是用空间换时间的提升性能的手段。出发点是缓解cpu或io资源。
    优点
        缓解cpu压力（计算密集型）
        缓解io压力 （i/o密集型）
    缺点：
        引入缓存会提高系统复杂度，需要考虑失效，更新，一致性问题
        会掩盖一些缺陷，让问题更久的时间才出现
        可能泄露某些保密资料，容易受到攻击

    缓存的四个维度
        吞吐量：反映了对缓存进行并发读，写操作的效率（如何设计并发数据竞争问题）
        命中率：反映引入缓存价值的高低（消耗空间与时间之间的平衡，需要淘汰缓存价值较低的数据）
        扩展功能：除了读写还有其他额外的功能（失效时间，淘汰策略，统计信息，持久化，集群，命中率等）
        分布式支持：可在多节点共享使用，减少单节点问题（涉及网络传输，序列化/反序列化）
            复制式缓存：(客户端) ————很少更新但频繁读取（已经很少用）
                每个节点都存在一份副本。当数据发送变化时需要遵循复制协议同步到每个节点
            集中式缓存：（服务器）————频繁更新（主流）
                redis成为集中式缓存首选

        CP保证强一致性的zookeeper，doozerd，etcd (配置)
        AP保证最终一致性redis

    缓存穿透
        缓存目的是为了缓解cpu或io压力，譬如对数据库做缓存，大部分流量可以从缓存中返回，只有未命中的才会流到数据库。减少数据库的压力。单如果数据库也不存在的话，此类流量每次都会经过缓存然后在穿通到数据库，缓存起不到任何作用。
            1.对业务逻辑不可避免的缓存穿透，
                对请求参数做判断，排除一些一定不存在的数据，
                本身数据库为空的数据，应该对数据做空处理，把空数据页加入到缓存中。
            2.对恶意攻击导致的缓存传统，在缓存前设置一个布隆过滤器。    

    缓存击穿
        基本工作原理预加载数据。如果某个热点缓存因某个原因失效了，全部流量都往数据库去了。
            1.热点数据手动管理，不设置过期时间，
            2.加同步锁，同时只允许一个请求流入数据库   

    缓存雪崩
        大量缓存同时无法命中情况下，这些请求同时到了数据库
            1.在过期时间上加上随机时间，分开同时过期时间
            2.提高缓存系统可用性，采用集群
            3.开启多级缓存          

    缓存污染
        与数据源数据不一致现象。追求强一致性。
            1.读数据时，先读缓存（无缓存时，读数据源在放入缓存）
            2.写数据时，先写数据源，然后失效缓存
                避免把缓存失效后再写数据源
                    如果这个时候有数据读取，加载缓存存储，然后在写数据源。此时缓存是旧数据
                应当让缓存失效而不是更新。
                    如果在更新缓存的过程中，其他数据源又被修改，然后比之前的更新缓存还早处理，那么此时缓存是旧数据。