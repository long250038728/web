### 提升大规模数据库查询性能的关键策略
当表的数据量超过一定规模（例如2000万行）时，由于B+树的层级增加，查询数据时会进行更多次的磁盘随机读取操作，从而增加了查询时间并导致响应速度变慢。这是因为随着数据量的增加，B+树的高度会相应增长，每次查询需要访问更多的节点，而这些节点可能存储在不同的磁盘位置，导致更多的磁盘I/O操作。优化此问题的方法包括但不限于使用分区表、增加索引缓存、优化查询、垂直或水平分割数据等。

分表和分区在数据库优化中具有重要意义，尤其是在处理大规模数据时有显著的效果
* 提高查询性能（当指定了分区键后查询到的数据只在对应的表/分区查询）
* 行锁及表锁的影响（当对数据加锁时由于数据存放在不同的表/分区中，加锁只会在对应的区域进行加锁）
* 提高并行能力（由于是多个逻辑存储上，可以充分利用cpu的多核处理能力）


### 分表分区
#### 分表
* 优势: 提高了数据的灵活性，可以根据不同的规则把数据存放到对应的地方。避免减少其他因素而影响到数据的准确性
* 劣势: 需要单独维护数据的存放位置。对表新增/修改字段时需要维护多个表。查询数据时需要确定在哪个表后才能进行查询。

#### 分区
* 优势: 简化了数据库的复杂性。无需管理表中是一个表/分区还是多个。同时在查询时无需再应用层面进行逻辑判断及处理。
* 劣势: 在查找或新增/修改时数据库会根据查询的条件选择分区，增加了数据库的一些逻辑判断有一定的性能影响。


### 分区实现
选择分区是项目应用层无需修改，只需要在mysql创建时指定分区的类型及数量数据库就会黑盒的处理对应的分区功能。在创建分区时通常有两种实现方式，主要为了适应不同的使用场景。

* 新建表
该方式是通过创建新表，数据手动迁移后对表名替换。该好处就是在迁移过程中原表数据可以正常对外进行访问及操作，减少了不可用的时间。同时避免大事务对主从库的影响。
```
CREATE TABLE zby_stock_change_log_new (
    id INT NOT NULL AUTO_INCREMENT,
    merchant_id INT NOT NULL,
    ...
    PRIMARY KEY (id,merchant_id)
)
PARTITION BY HASH (merchant_id)
PARTITIONS 32;

INSERT INTO zby_stock_change_log_new SELECT * FROM zby_stock_change_log WHERE id BETWEEN 1 AND 100000;

RENAME TABLE zby_stock_change_log TO zby_stock_change_log_backup, zby_stock_change_log_new TO zby_stock_change_log;
```

* ALTER TABLE
会对表进行加锁,此时如果有数据的修改时就会阻塞甚至超时。该操作适合数据量较小且在非繁忙时段操作。优势在意无需人为手动迁移数据。整个迁移都在同个事务中执行，确保了数据的一致性
```
ALTER TABLE zby_stock_change_log DROP PRIMARY KEY,ADD PRIMARY KEY(`id`,`merchant_id`);
ALTER TABLE zby_stock_change_log partition by HASH(merchant_id) partitions 32;
```


### 分表实现
分表时就是创建结构与原先表相同结构的表。在代码层面对指定数据到对应的表中
```
CREATE TABLE zby_stock_change_log_part_1 LIKE zby_stock_change_log;
CREATE TABLE zby_stock_change_log_part_2 LIKE zby_stock_change_log;
CREATE TABLE zby_stock_change_log_part_3 LIKE zby_stock_change_log;
```

#### 代码伪实现
* 原生sql时就需要把表名根据函数返回的替换对应的表名。
* ORM时GORM及ThinkPHP中，ORM查询的表时是根据模型定义的类名进行获取。如果表进行分表后新增各个模型就会导致相同类似的模型很多。同时很多在模型中实现的方法就不能复用或需要抽离出单独函数。好在这两个框架都提供对应的方法进行处理。在创建该模型后如果指定了表名，在执行sql时会更加传入的表名为优先，不传则根据模型名进行获取。
```
GORM: 
    db.Table(表名).find() //（含前缀）
thinkphp: 
    (new User)->setTable(表名)->select()->toArray(); //（含前缀）
    (new User)->name(表名)->select()->toArray(); //（不含前缀）
medoo:
    (new User)->setTable(表名)->xxxxx; //（不含前缀）
```



* go GORM
```
const (
	Customer = "zby_customer"
)

func pTableName(table string, partitionKey int32) string {
	//分表逻辑TODO
	return table + "_part_1"
}

type User struct {
	MerchantId int32
	Name       string
	Id         int
}

//========================================================================

// 插入
func TestCreate(t *testing.T) {
	// 插入
	user := &User{MerchantId: 1, Id: 1, Name: "linl"}
	db.Table(pTableName(Customer, 1)).Create(&user)

	// 批量插入
	users := []*User{
		{MerchantId: 1, Id: 2, Name: "linl1"},
		{MerchantId: 1, Id: 3, Name: "linl2"},
	}
	db.Table(pTableName(Customer, 1)).Create(&users)

	// 分批批量插入
	userBatches := []*User{
		{MerchantId: 1, Id: 4, Name: "linl1"},
		{MerchantId: 1, Id: 5, Name: "linl2"},
		{MerchantId: 1, Id: 6, Name: "linl2"},
		{MerchantId: 1, Id: 7, Name: "linl2"},
		{MerchantId: 1, Id: 8, Name: "linl2"},
	}
	db.Table(pTableName(Customer, 1)).CreateInBatches(&userBatches, 2)
}

// 查询
func TestSelect(t *testing.T) {
	//单个
	var user *User
	db.Table(pTableName(Customer, 1)).Where("id < 10").Find(&user)
	t.Log(user)

	//多个
	var users []*User
	db.Table(pTableName(Customer, 1)).Where("id < 10").Find(&users)
	for _, val := range users {
		t.Log(val)
	}

	//take方法
	var userTake *User
	db.Table(pTableName(Customer, 1)).Where("id < 10").Take(&userTake)
	t.Log(userTake)

	//first方法
	var userFirst *User
	db.Table(pTableName(Customer, 1)).Where("id < 10").First(&userFirst)
	t.Log(userFirst)

	//last方法
	var userLast *User
	db.Table(pTableName(Customer, 1)).Where("id < 10").Last(&userLast)
	t.Log(userLast)
}

// 更新
func TestUpdate(t *testing.T) {
	//根据模型
	var users = []*User{
		{Id: 1, Name: "xx1", MerchantId: 2},
		{Id: 2, Name: "xx2", MerchantId: 2},
		{Id: 3, Name: "xx3", MerchantId: 2},
	}
	for _, val := range users {
		t.Log(db.Table(pTableName(Customer, 1)).Updates(&val).Error)
	}

	// 根据map
	updateData := map[string]interface{}{
		"name": "yyyy",
	}
	t.Log(db.Table(pTableName(Customer, 1)).Where("id = ? ", 4).Updates(updateData).Error)
	
	//更新单值
	t.Log(db.Table(pTableName(Customer, 1)).Where("id = ? ", 5).UpdateColumn("name", "zzz").Error)
	t.Log(db.Table(pTableName(Customer, 1)).Where("id = ? ", 6).Update("name", "xyz").Error)
}


// 删除
func TestDelete(t *testing.T) {
	// 根据条件
	t.Log(db.Table(pTableName(Customer, 1)).Where("id = ? ", 7).Delete(nil).Error)

	// 根据模型
	user := &User{Id: 8, Name: "xx1", MerchantId: 2}
	t.Log(db.Table(pTableName(Customer, 1)).Delete(user).Error)
}

```

* PHP ORM (thinkphp)
```
// 查询 (新增,删除,修改处理方式相同)
$db = new User;
$user = $db->where("id",1)->find()->toArray();             //SELECT * FROM `zby_user` WHERE  `id` = 1 LIMIT 1
$users = $db->where("id",1)->select()->toArray();          //SELECT * FROM `zby_user` WHERE  `id` = 1

$db = (new User)->name("customer");
$user = $db->where("id",1)->find()->toArray();             //SELECT * FROM `zby_customer` WHERE  `id` = 1
$users = $db->where("id",1)->select()->toArray();          //SELECT * FROM `zby_customer` WHERE  `id` = 1
```

* PHP medoo 
```
// 查询 (新增,删除,修改处理方式相同)
$db = (new CustomerTable());
$user = $db->findOne(["AND" => ["id" => 1]],"*");   // SELECT * FROM `zby_customer` WHERE `id` = 1 LIMIT 1
$users = $db->getItems("*",["AND" => ["id" => 1]]); // SELECT * FROM `zby_customer` WHERE `id` = 1
        
$db = (new CustomerTable())->setTable("user");
$user = $db->findOne(["AND" => ["id" => 1]],"*");   // SELECT * FROM `zby_user` WHERE `id` = 1 LIMIT 1
$users = $db->getItems("*",["AND" => ["id" => 1]]); // SELECT * FROM `zby_user` WHERE `id` = 1
```


### 旧数据处理
整个数据跑完可能需要几个小时系统不能停机升级。所以需要提前创建及跑部分数据。由于白天繁忙时间不可大规模写数据所以需要提前一天或几天。代码上线后，在把接下来没跑完的数据跑完，
zby_stock_change_log 的xxx时间为开始跑数据的时间
zby_stock_check_record 的xxx时间可能需要提前一个月或更长的时间（盘点一般不会修改到一个月之前的数据）

只增不改zby_stock_change_log
```
INSERT INTO zby_stock_change_log_part_1 SELECT * FROM zby_stock_change_log WHERE merchant_id = 1 and create_time <= xxxx;
INSERT INTO zby_stock_change_log_part_2 SELECT * FROM zby_stock_change_log WHERE merchant_id = 200 and create_time <= xxxx;

发布代码上线后

INSERT INTO zby_stock_change_log_part_1 SELECT * FROM zby_stock_change_log WHERE merchant_id = 1 and create_time > xxxx;
INSERT INTO zby_stock_change_log_part_2 SELECT * FROM zby_stock_change_log WHERE merchant_id = 200 and create_time > xxxx;
```

能增加能改zby_stock_check_record
```
INSERT INTO zby_stock_check_record_part_1 SELECT * FROM zby_stock_check_record WHERE merchant_id = 1 and create_time <= xxxx;
INSERT INTO zby_stock_check_record_part_2 SELECT * FROM zby_stock_check_record WHERE merchant_id = 200 and create_time <= xxxx;

发布代码上线后

INSERT INTO zby_stock_check_record_part_1 SELECT * FROM zby_stock_change_log WHERE merchant_id = 1 and create_time > xxxx;
INSERT INTO zby_stock_check_record_part_2 SELECT * FROM zby_stock_change_log WHERE merchant_id = 200 and create_time > xxxx;
```


### 需要探讨的问题
1. 需要定义多少个分表 （由于分表维护起来比分区困难，不能像分区一样创建32个分区） 
2. 分表的拆分规则 （merchant_id  (1 - 500)  (501 - 1000) (1001 - 1500) (1501 - 2000) (2000 - 无限) ）
3. zby_stock_check_record表业务独立，只有kobe项目使用。可否先通过zby_stock_check_record为试点功能（无需考虑thinkphp，medoo，及各个实际业务）
4. 由于我们的id为自增id。多个表的id相同是否能接受。如果不接受是否还需要考虑雪花算法等。
5. 由于分表以后新增/修改字段就需要人员维护，如果中间少处理个表，可能就会导致业务报错