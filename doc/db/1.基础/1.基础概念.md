### MySQL架构图
- server
  * 连接器 (会连接的用户进行权限的检查，长连接的超时及断开)
  * 分析器 (分析语句的词法，语法是否有误)
  * 优化器 (根据语句进行索引的选择，多表关联的顺序等)
  * 执行器 (调用引擎层下面的引擎，同时判断表级别是否有权限)
    - 在慢日志中可以看到rows_examined字段表示调用了多少引擎获取的数据（虽然执行器调用一次但引擎内部可能扫描了多行）
- 引擎层
  * innodb (行锁,有事务)
  * myisam (只有表锁，无事务)
  * 等等


### MySQL更新流程
1. server层: 通过执行器调用引擎层获取数据
2. 引擎层: 从buffer pool或磁盘读取数据返回给server层
3. server层: 获取数据后对数据进行更新，调用引擎层保存操作 `**注意：是在sever层做的计算处理 **`
4. 引擎层: 把数据写入到buffer pool后同时写入redo log日志，此时redo log的状态是prepare状态。返回server层redo log写入成功 `这里用到两阶段提交` 
5. server层: 接收到成功后写入binlog日志，同时调用引擎层提交事务。同时binlog发给从库(从库通过io线程获取，然后到了relay线程加载，最后到io线程`并行`执行) `有个XID绑定用于恢复时保证两个日志是否成对，如果成对则代表成功`
6. 引擎层: 把redo log 更新为commit状态


### redo log 与 binlog 两阶段提交补充
1. redo log处于prepare状态，binlog还未写入此时崩溃。恢复后binlog没写会回滚
2. redo log处于prepare状态，binlog写完时崩溃。判断binlog是否完整，非完整则回滚(完整判断：statement格式最后有个commit，row格式有个`XID` event)
3. redo log 跟 binlog关联 有共同的`XID`进行关联
4. binlog 在事务执行的过程中先写到binlog cache中，等到`事务提交`的时候才写到binlog文件中，清空binlog cache
   * binlog格式 （binlog中有server id，用于循环复制问题）
     * statement : sql原文  
     * row :  替换成两个event：Table_map(哪个表)和 XXXX_rows(什么操作) 还有具体操作  (数据量大)
     * mixed :  当主备可能不一致用row，主备不会不一致用statement
5. redo log 在事务执行过程中先写到redo log buffer中，事务还`没提交`有`可能`被持久到磁盘(如果事务回滚时会通过undo log生成新的redo log)
   * 后台有线程每隔1s会把redo log buffer日志调用write到 page cache。然后调用fsync持久化到磁盘
   * redo log buffer空间到innodb_log_buffer_size 大小的一半时，会执行write操作到 page cache。（此时不会调用fsync持久化到磁盘）
   * 并行的事务提交时，也会顺便把其他事务的redo log buffer ，会执行write操作到 page cache。(是否fsync持久化到磁盘根据配置innodb_flush_log_at_trx_commit)
   * 组提交
     * LSN (全局唯一)用来对应redo log 的一个个写入点，长度为len 的redo log，LSN的值会加上len
     * LSN 也会写入到innodb数据页中，确保数据页不会多次重复执行redo log。 多个事务的写入时，LSN取最大的，此时小于这个LSN则表示已经持久化到磁盘，则可以直接返回


### MySQL count
1. count(字段): innodb会遍历表把`字段`返回给sever层，判断不为空则sever层加1，否则不处理
2. count(id): innodb会遍历表把`id`返回给sever层，判断不为空则sever层加1，否则不处理
3. count(1): innodb会遍历表`不取值`，返回1给server层，server加1
4. count(*) : 优化是count(1)的优化，可认为是count(1)


### Order(Using filesort)
两种排序方式: `max_length_for_sort_data` 行数据是否超过设置大小。 如果避免排序计算可以考虑添加索引（空间换时间）
1. `全字段`排序（把`整行`数据放入sort buffer中，然后排序返回）———— 能用内存就尽量用内存，但是考虑内存太大效率不高，就用rowid
2. `rowid`排序 (把排序`字段`及id放入sort buffer中，然后排序`回表`返回) ———— 回表多一次不会优先考虑行数据过大才考虑


### 查询变慢的原因
1. 等待MDL锁（可执行show processlist验证）
2. 刷脏页
3. 等待其他事务锁
4. 有其他大事务，查询时需要通过undo log回滚找回数据

### 幻读
1. 可重复度解决幻读的问题，是通过next_lock key锁。把锁的力度加大，避免其他事务`插入`成功


### GTID
1. 主备切换时从节点在切换master时以前是通过需要设置binlog的文件及位置，获取这些信息比较麻烦，同时还可能有报错的问题，此时就引入`GTID`的概念
2. 在连接时从库把本地的`GTID`集合发给主库，与主库的`GITD`集合求差集，这样就知道从库还有什么`GTID`未被同步，根据binlog的事件头部`GTID`就知道哪些binlog可以忽略，哪些binlog需要执行


### 主从同步
* 异步复制
  * master两阶段提交binlog及redo log后视为成功，返回客户端
    * 主库： SHOW VARIABLES LIKE 'rpl_semi_sync_master_enabled'; == OFF
    * 主库： SHOW STATUS LIKE 'rpl_semi_sync_master_status'; == OFF
    * 从库： SHOW VARIABLES LIKE 'rpl_semi_sync_slave_enabled'; == OFF
    * 从库： SHOW STATUS LIKE 'Rpl_semi_sync_slave_status';  == OFF
* 半同步复制
  * master两阶段提交binlog及redo log后，slave接收到binlog（io线程获取，写入relay log）时视为成功，返回给客户端
    * 主库： SHOW VARIABLES LIKE 'rpl_semi_sync_master_enabled'; == ON
    * 主库： SHOW STATUS LIKE 'rpl_semi_sync_master_status'; == ON
    * 从库： SHOW VARIABLES LIKE 'rpl_semi_sync_slave_enabled'; == ON
    * 从库： SHOW STATUS LIKE 'Rpl_semi_sync_slave_status';  == ON
    * 检查插件是否加载 SELECT PLUGIN_NAME,PLUGIN_STATUS FROM INFORMATION_SCHEMA.PLUGINS WHERE PLUGIN_NAME LIKE 'rpl_semi_sync%';
      1. INSTALL PLUGIN rpl_semi_sync_master SONAME 'semisync_master.so'; 
      2. INSTALL PLUGIN rpl_semi_sync_slave SONAME 'semisync_slave.so';
* 组复制
  * 采用paxos或raft一致性协议，多个实例组成，当进过多半数确认则认为成功，返回给客户端（单主模式，多主模式）
    * SELECT VARIABLE_VALUE FROM PERFORMANCE_SCHEMA.global_variables WHERE VARIABLE_NAME='group_replication_group_name'; //组复制名称
    * SHOW STATUS LIKE 'group_replication%'; //查看组复制的当前状态
      * group_replication_primary_member 主要节点（单主模式）
      * group_replication_member_state  成员状态 (ONLINE节点正常,RECOVERING节点正在恢复,ERROR节点异常)
    * SELECT * FROM performance_schema.replication_group_members;
      * MEMBER_ID组成员ID   MEMBER_HOST组成员IP地址   MEMBER_STATE当前状态(ONLINE/RECOVERING/ERROR)  MEMBER_ROLE角色(PRIMARY/SECONDARY)
    * 检查插件是否加载 SELECT PLUGIN_NAME,PLUGIN_STATUS FROM INFORMATION_SCHEMA.PLUGINS WHERE PLUGIN_NAME='group_replication';


### 读写分离数据一致问题
1. 强制读主库方案 （从业务入手 ———— 判断哪些业务适合读从库，哪些业务时读主库）
2. sleep方案 （从业务入手 ———— 插入更新操作返回新数据，或从交互方式延迟请求）
3. 判断主从延迟 show slave status(seconds_behind_master但是是秒，大于0一定是有延迟，等于0不一定没延迟)
4. 等主库位点  show slave status(Read_Master_Log_Pos读主库最新位点,Exec_Master_Log_Pos执行从库最新位点) ———— 如果还没传到库位点，也是有延迟
5. 等GTID方案  show slave status(Retrieved_Gtid_Set读主库最新GTID,Executed_Gtid_Set执行从库最新位点)   ———— 如果还没传到库GTID，也是有延迟
6. 配合semi-sync 当从库收到binlog的时候返回ack后，主库才能返回给客户端成功
    * 一主一从可以结合 semi-sync + GTID 方案 (但是是针对整个库的有可能始终都判断有延迟颗粒度太大) 。
    * 一主多从如果使用 semi-sync的话，读的正好是没有semi-sync的那台依旧是过期读
7. `select master_pos_wait(file,pos[,timeout])` 或 ` select wait_for_executed_gtid_set(gtid_set, 1)`
   1. 在master执行`show master status` 当前主库执行到的 File 和 Position 或 Executed_Gtids_Set；
   2. 在从库执行 select master_pos_wait(File,1Position,1) 返回值 >=0 可在从库获取，否则取主库数据
   3. 在从库执行 select wait_for_executed_gtid_set(Executed_Gtids_Set,1) 返回值 0 可在从库获取，否则取主库数据

    
### 临时表
1. 只有在当前session查看，其他线程不可见。 session结束后自动删除
2. 可以与正常表格同名(优先取临时表)，不同session临时表名相同不影响 (进程+线程+序列化.frm文件 ， 临时表空间保存不用ibd)
3. 如果binlog的格式设置为row时，binlog不记录临时表相关的数据（在`insert into select 临时表`时由于binlog有真实数据所以临时表不同步到从库也能正常写入）
4. 系统在union（需要去重所以需要临时表暂存） ,group by (同样需要去重与求和需要临时表暂存) ———— 前提是buffer放不下


### 其他
1. Memory引擎（数据结构时数组，保存在内存他快但是无法持久化及不支持行锁），扫描时是查询数组，当需要有序时可以创建b-tree索引 （临时表可以使用Memory引擎其他场景还是使用innodb引擎）
2. 主键自增id不一定连续 (插入时分配，回滚时不回收，因为回收导致数据顺序有问题), 批量插入时id的申请是通过批量申请多个，中间用不到可能就导致空洞
3. insert A Select B 时， 会锁表B`行读锁`，还有表A的`表写锁` （由于行读锁扫描到才加锁，当还没扫描的行数据有另外一个session更新可以更新成功，但是由于mvvc的隔离级别，读到的数据还是之间的数据）
4. 快速复制表 使用mysqldump方法把数据导出insert sql语句避免原表有影响（行锁即并发问题）。 使用ibd的方式（云服务无法直接操作）
   * sql:    create table r like t; //创建表r
   * sql:    alter table r discard tablespace; //删除r的空间
   * sql:    flush table t for export; //生成一个t.cfg文件  从flush table 到 unlock tables中间是会对表t加锁的
   * shell:  cp t.cfg r.cfg; cp t.ibd r.ibd // 拷贝
   * shell:  chown -R mysql:mysql r.* // 设置权限
   * sql:    unlock tables; // t.cgf文件删除
   * sql:    alter table r import tablespace; // r.ibd文件作为表r的新的表空间  这个时间也会较长
5. grant授权语句（在磁盘user,db等表更新，内存中找对象更新）， flush privileges语句会清空内存对象（手动操作表才要执行）
   * 全局权限: mysql.user表 &&  内存数组acl_users 。 创建连接会拷贝到自己的线程对象中 。 所以全局不对已经连接的有影响 （可能考虑到不会经常变动）
   * db权限: mysql.db表 &&  内存数组acl_dbs。会影响已经存在的连接 （需要实时校验）
   * 表权限及列权限： mysql.columns_priv表 && 内存的hash结构column_priv_hash 。会影响已经存在的连接 （需要实时校验）
6. 分区表。MDL锁力度大。
   * 通用分区： MyISAM引擎： 在server分区，所以会调用引擎获取所有分区的数据。如果超过open_file_limit会报错
   * 本地分区： innodb引擎： 在innodb引擎层分区。只会打开实际需要访问的分区文件。
7. id用完会怎样
   * `AUTH_INCREMENT自增id`表的自增id达到上限后，再申请时它的值就不会改变，进而导致继续插入数据时报主键冲突 的错误。 （2的32次方 -1） 
   * `row_id`达到上限后，则会归0再重新递增，如果出现相同的row_id，后写的数据会覆盖之前的数据。（应该主动创建自增主键用完会主键冲突） （2的48次方 -1） 
   * `Xid`只需要不在同一个binlog文件中出现重复值即可。虽然理论上会出现重复值，但是概率极小，可以忽略不计。 （2的64次方 -1）  `(Server层)`
   * `InnoDB的max_trx_id` 递增值每次MySQL重启都会被保存起来，所以我们文章中提到的脏读 的例子就是一个必现的bug，好在留给我们的时间还很充裕。 （2的48次方 -1）` (innodb层)`
   * `thread_id`是我们使用中最常见的，而且也是处理得最好的一个自增id逻辑了  （2的32次方 -1） 

    
---

### 参数
* wait_timeout: 控制空闲时间超时时间(默认8个小时)
* transaction_isolation: 控制事务隔离级别(默认为REPEATABLE READ)
* innodb_page_size: 控制innodb引擎的页面大小(默认16KB)
* innodb_lock_wait_timeout: 控制innodb引擎的等待超时时间(默认50秒)合理控制太短会导致误伤
* innodb_deadlock_detect: 是否开启死锁检测(默认开启)
* innodb_change_buffer_max_size: 代表占buffer pool的百分比，默认为25%
* innodb_io_capacity: 代表innodb引擎的io能力，默认为2000，单位为KB(用户刷脏页能力)
* innodb_max_dirty_pages_pct: 代表脏页占buffer pool的百分比，默认为75%
* innodb_flush_neighbors: 刷脏页时旁边的也是脏页，也带同刷脏页，默认0
* innodb_file_per_table: 代表每个表一个数据文件(0表示放在共享空间，1每个单独的idb空间)，默认为1
* sort_buffer_size: 代表排序缓冲区大小，默认为256KB,如果超过使用临时文件(Using temporary)
* max_length_for_sort_data: 单行排序数据大小（超过则会使用rowid排序，否则使用全字段排序），默认为8MB
* tmp_table_size: 代表临时表大小，默认为64MB
* binlog_cache_size: 代表binlog缓冲区大小，默认为1MB.超过时会暂存到磁盘
* innodb_log_buffer_size: 当redo log buffer大小到一半时会回执行fsync
* sync_binlog: 代表binlog同步到磁盘，建议1 (0:事务提交只write不fsync      1:每次事务提交都会fsync    n: 累计n个后才fsync)
* innodb_flush_log_at_trx_commit: 建议1 (0:事务提交只把redo log留在 redo log buffer中     1:每次事务提交会写入持平中     2:每次事务提交吧redo log写入到page cache中)
* binlog_group_commit_sync_delay: 代表binlog group commit同步延迟，默认为0
* binlog_group_commit_sync_no_delay_count: 代表积累多少次才调用fsync
* innodb_thread_concurrency : 代表innodb并发查询，默认为0，表示不限制

### sql语句
* select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started)) > 60; //检查长事务
* show index from `table_name`; //查看索引信息
* analyze table `table_name`; //重新计算统计信息
* alter table `table_name` engine=InnoDB; //重建表
* optimize table `table_name`; //  analyze table table_name  + alter table table_name engine=InnoDB
* show table status; //查看表信息(这是预估统计)
* show processlist; //查看连接数据
* SET optimizer_trace="enabled=on"; &&  select **** from `table_name`;   &&   SELECT * FROM information_schema.OPTIMIZER_TRACE;  //查看优化器信息
* show slave status; //备库的状态
* EXPLAIN ANALYZE select **** from `table_name` //查看执行计划（真实执行，如果update会回滚）
  * Table scan on 表  					 	   //全表扫描（使用主键）
  * Index scan on 表 using 索引  	           //索引扫描(区间查询)
  * Index lookup on 表 using 索引              //索引扫描(等值查询)
  * Index scan using 索引 (skip scan) on 表    //Using index for skip scan 8.0优化为了避免最左匹配原则无法使用索引的问题(通过索引找出前面的值，虽然会多少扫描但性能比全表快)
 
### 工具 
1. mysqldump 数据导入导出
```
选项	描述
-u, --user=用户名	指定 MySQL 用户名
-p[密码], --password[=密码]	指定 MySQL 密码
-h, --host=主机名	指定 MySQL 主机
-P, --port=端口号	指定 MySQL 端口
-d, --no-data	不导出数据，仅导出结构
--all-databases	导出所有数据库
--databases	导出多个数据库
--tables	导出指定的表
--where=条件	导出满足条件的数据
--add-drop-database	在创建数据库前添加 DROP DATABASE 语句
--add-drop-table	在创建表前添加 DROP TABLE 语句
--comments	在输出中添加注释
--complete-insert	使用完整的 INSERT 语句（包含列名）
--create-options	在 CREATE TABLE 语句中包含选项
--disable-keys	在导出中禁用外键检查
--extended-insert	使用扩展的 INSERT 语句
--flush-logs	在备份前刷新日志
--lock-all-tables	锁定所有表
--lock-tables	锁定所有表（默认）
--no-set-names	不设置字符集
--opt	启用多种优化选项（默认启用）
--routines	导出存储过程和函数
--triggers	导出触发器
--set-gtid-purged=选项	设置 GTID purged 选项
--single-transaction	使用单一事务导出（适用于 InnoDB）
--skip-comments	不在输出中添加注释
--skip-lock-tables	不锁定表
--skip-set-charset	不设置字符集
--tab=目录	将每个表导出为一个文件

mysqldump  \
-u root \
--password=root123456 \
--single-transaction \
online \
> d.sql
```

2. mysqlbinlog binlog分析工具
```
选项	描述
-d, --database=数据库名	仅显示指定数据库的操作
-v	以详细模式显示事件
-vv	以更详细的模式显示事件
--start-datetime=日期时间	从指定日期时间开始显示事件
--stop-datetime=日期时间	到指定日期时间为止显示事件
--start-position=位置	从指定位置开始显示事件
--stop-position=位置	到指定位置为止显示事件
--result-file=文件名	将输出保存到指定文件
--read-from-remote-server	从远程服务器读取二进制日志
--host=主机名	连接远程服务器的主机名
--port=端口号	连接远程服务器的端口号
--user=用户名	连接远程服务器的用户名
--password[=密码]	连接远程服务器的密码
--socket=套接字文件	连接远程服务器的套接字文件路径
--no-defaults	不加载默认配置文件
--force-read	忽略无法识别的事件并继续处理
--hexdump	在注释中显示日志的十六进制转储
--short-form	仅显示日志中的语句，不显示其他信息

./mysqlbinlog \
 --database="online" \
 --start-datetime="2024-01-01 00:00:00" \
 --stop-datetime="2025-10-01 00:00:00" \
 --start-position=8803 \
 -stop-position=9034 \
 -vv \
 /var/lib/mysql/binlog.000020
```

----

# 锁看是否需要重新整理 06 07  结合会议视频
1. 把容易照成锁冲突的，影响并发的尽量往后放
2. 死锁：业务不会出现。并发控制


08 有问题
21 22 没读，非常重点
40 重读，非常重点
23 - 30  只要看文章就可以，已经看过但怕忘记重温
40  重读，非常重点