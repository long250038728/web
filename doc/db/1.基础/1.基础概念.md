### MySQL架构图
- server
  * 连接器 (会连接的用户进行权限的检查，长连接的超时及断开)
  * 分析器 (分析语句的词法，语法是否有误)
  * 优化器 (根据语句进行索引的选择，多表关联的顺序等)
  * 执行器 (调用引擎层下面的引擎，同时判断表级别是否有权限)
    - 在慢日志中可以看到rows_examined字段表示调用了多少引擎获取的数据（虽然执行器调用一次但引擎内部可能扫描了多行）
- 引擎层
  * innodb (行锁,有事务)
  * myisam (只有表锁，无事务)
  * 等等


### MySQL更新流程
1. server层: 通过执行器调用引擎层获取数据
2. 引擎层: 从buffer pool或磁盘读取数据返回给server层
3. server层: 获取数据后对数据进行更新，调用引擎层保存操作 `**注意：是在sever层做的计算处理 **`
4. 引擎层: 把数据写入到buffer pool后同时写入redo log日志，此时redo log的状态是prepare状态。返回server层redo log写入成功 `这里用到两阶段提交` 
5. server层: 接收到成功后写入binlog日志，同时调用引擎层提交事务。同时binlog发给从库(从库通过io线程获取，然后到了relay线程加载，最后到io线程`并行`执行) `有个XID绑定用于恢复时保证两个日志是否成对，如果成对则代表成功`
6. 引擎层: 把redo log 更新为commit状态


### redo log 与 binlog 两阶段提交补充
1. redo log处于prepare状态，binlog还未写入此时崩溃。恢复后binlog没写会回滚
2. redo log处于prepare状态，binlog写完时崩溃。判断binlog是否完整，非完整则回滚(完整判断：statement格式最后有个commit，row格式有个`XID` event)
3. redo log 跟 binlog关联 有共同的`XID`进行关联
4. binlog 在事务执行的过程中先写到binlog cache中，等到`事务提交`的时候才写到binlog文件中，清空binlog cache
   * binlog格式 （binlog中有server id，用于循环复制问题）
     * statement : sql原文  
     * row :  替换成两个event：Table_map(哪个表)和 XXXX_rows(什么操作) 还有具体操作  (数据量大)
     * mixed :  当主备可能不一致用row，主备不会不一致用statement
5. redo log 在事务执行过程中先写到redo log buffer中，事务还`没提交`有`可能`被持久到磁盘(如果事务回滚时会通过undo log生成新的redo log)
   * 后台有线程每隔1s会把redo log buffer日志调用write到 page cache。然后调用fsync持久化到磁盘
   * redo log buffer空间到innodb_log_buffer_size 大小的一半时，会执行write操作到 page cache。（此时不会调用fsync持久化到磁盘）
   * 并行的事务提交时，也会顺便把其他事务的redo log buffer ，会执行write操作到 page cache。(是否fsync持久化到磁盘根据配置innodb_flush_log_at_trx_commit)
   * 组提交
     * LSN (全局唯一)用来对应redo log 的一个个写入点，长度为len 的redo log，LSN的值会加上len
     * LSN 也会写入到innodb数据页中，确保数据页不会多次重复执行redo log。 多个事务的写入时，LSN取最大的，此时小于这个LSN则表示已经持久化到磁盘，则可以直接返回


### MySQL count
1. count(字段): innodb会遍历表把`字段`返回给sever层，判断不为空则sever层加1，否则不处理
2. count(id): innodb会遍历表把`id`返回给sever层，判断不为空则sever层加1，否则不处理
3. count(1): innodb会遍历表`不取值`，返回1给server层，server加1
4. count(*) : 优化是count(1)的优化，可认为是count(1)


### Order(Using filesort)
两种排序方式: `max_length_for_sort_data` 行数据是否超过设置大小。 如果避免排序计算可以考虑添加索引（空间换时间）
1. `全字段`排序（把`整行`数据放入sort buffer中，然后排序返回）———— 能用内存就尽量用内存，但是考虑内存太大效率不高，就用rowid
2. `rowid`排序 (把排序`字段`及id放入sort buffer中，然后排序`回表`返回) ———— 回表多一次不会优先考虑行数据过大才考虑


### 查询变慢的原因
1. 等待MDL锁（可执行show processlist验证）
2. 刷脏页
3. 等待其他事务锁
4. 有其他大事务，查询时需要通过undo log回滚找回数据

### 幻读
1. 可重复度解决幻读的问题，是通过next_lock key锁。把锁的力度加大，避免其他事务`插入`成功


### GTID
1. 主备切换时从节点在切换master时以前是通过需要设置binlog的文件及位置，获取这些信息比较麻烦，同时还可能有报错的问题，此时就引入`GTID`的概念
2. 在连接时从库把本地的`GTID`集合发给主库，与主库的`GITD`集合求差集，这样就知道从库还有什么`GTID`未被同步，根据binlog的事件头部`GTID`就知道哪些binlog可以忽略，哪些binlog需要执行


### 读写分离数据一致问题
1. 强制读主库方案 （从业务入手 ———— 判断哪些业务适合读从库，哪些业务时读主库）
2. sleep方案 （从业务入手 ———— 插入更新操作返回新数据，或从交互方式延迟请求）
3. 判断主从延迟 show slave status(seconds_behind_master但是是秒，大于0一定是有延迟，等于0不一定没延迟)
4. 等主库位点  show slave status(Read_Master_Log_Pos读主库最新位点,Exec_Master_Log_Pos执行从库最新位点) ———— 如果还没传到库位点，也是有延迟
5. 等GTID方案  show slave status(Retrieved_Gtid_Set读主库最新GTID,Executed_Gtid_Set执行从库最新位点)   ———— 如果还没传到库GTID，也是有延迟
6. 配合semi-sync 当从库收到binlog的时候返回ack后，主库才能返回给客户端成功
    * 一主一从可以结合 semi-sync + GTID 方案 (但是是针对整个库的有可能始终都判断有延迟颗粒度太大) 。
    * 一主多从如果使用 semi-sync的话，读的正好是没有semi-sync的那台依旧是过期读
7. `select master_pos_wait(file,pos[,timeout])` 或 ` select wait_for_executed_gtid_set(gtid_set, 1)`
   1. 在master执行`show master status` 当前主库执行到的 File 和 Position 或 Executed_Gtids_Set；
   2. 在从库执行 select master_pos_wait(File,1Position,1) 返回值 >=0 可在从库获取，否则取主库数据
   3. 在从库执行 select wait_for_executed_gtid_set(Executed_Gtids_Set,1) 返回值 0 可在从库获取，否则取主库数据


---

### 参数
* wait_timeout: 控制空闲时间超时时间(默认8个小时)
* transaction_isolation: 控制事务隔离级别(默认为REPEATABLE READ)
* innodb_page_size: 控制innodb引擎的页面大小(默认16KB)
* innodb_lock_wait_timeout: 控制innodb引擎的等待超时时间(默认50秒)合理控制太短会导致误伤
* innodb_deadlock_detect: 是否开启死锁检测(默认开启)
* innodb_change_buffer_max_size: 代表占buffer pool的百分比，默认为25%
* innodb_io_capacity: 代表innodb引擎的io能力，默认为2000，单位为KB(用户刷脏页能力)
* innodb_max_dirty_pages_pct: 代表脏页占buffer pool的百分比，默认为75%
* innodb_flush_neighbors: 刷脏页时旁边的也是脏页，也带同刷脏页，默认0
* innodb_file_per_table: 代表每个表一个数据文件(0表示放在共享空间，1每个单独的idb空间)，默认为1
* sort_buffer_size: 代表排序缓冲区大小，默认为256KB,如果超过使用临时文件(Using temporary)
* max_length_for_sort_data: 单行排序数据大小（超过则会使用rowid排序，否则使用全字段排序），默认为8MB
* tmp_table_size: 代表临时表大小，默认为64MB
* binlog_cache_size: 代表binlog缓冲区大小，默认为1MB.超过时会暂存到磁盘
* innodb_log_buffer_size: 当redo log buffer大小到一半时会回执行fsync
* sync_binlog: 代表binlog同步到磁盘，建议1 (0:事务提交只write不fsync      1:每次事务提交都会fsync    n: 累计n个后才fsync)
* innodb_flush_log_at_trx_commit: 建议1 (0:事务提交只把redo log留在 redo log buffer中     1:每次事务提交会写入持平中     2:每次事务提交吧redo log写入到page cache中)
* binlog_group_commit_sync_delay: 代表binlog group commit同步延迟，默认为0
* binlog_group_commit_sync_no_delay_count: 代表积累多少次才调用fsync
* innodb_thread_concurrency : 代表innodb并发查询，默认为0，表示不限制


### sql语句
* select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started)) > 60; //检查长事务
* show index from `table_name`; //查看索引信息
* analyze table `table_name`; //重新计算统计信息
* alter table `table_name` engine=InnoDB; //重建表
* optimize table `table_name`; //  analyze table table_name  + alter table table_name engine=InnoDB
* show table status; //查看表信息(这是预估统计)
* show processlist; //查看连接数据
* SET optimizer_trace="enabled=on"; &&  select **** from `table_name`;   &&   SELECT * FROM information_schema.OPTIMIZER_TRACE;  //查看优化器信息
* show slave status; //备库的状态
 
### 工具 
1. mysqldump 数据导入导出
2. mysqlbinlog binlog分析工具
----

# 锁看是否需要重新整理 06 07  结合会议视频
1. 把容易照成锁冲突的，影响并发的尽量往后放
2. 死锁：业务不会出现。并发控制


08 有问题
21 22 没读，非常重点