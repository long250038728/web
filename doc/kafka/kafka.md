### 生产者消费者基础
#### 生产者
TCP连接管理
1. 初始化创建连接
2. 使用时创建连接（懒式加载）

心跳检查
1. TCP中的KeepAlive保活机制（服务器发出检测）
2. 应用层主动探测（客户端主动ping-pong）

错误处理
* 可重试：连接断开，网络抖动，leader切换，超时，服务器异常（Warning）
* 不可重试：topic不存在，broker不存在，集群与broker无响应（Error）

寻址机制（分区会在集群的不同节点上，写入数据时如何确定节点）
* metadata：客户端启动/定期更新/请求错误更新 =》 把元数据拉取（主题下leader是谁，rep有谁）
* 服务端转发：随机写到某台broker，内部在根据信息进行转发（客户端开发成本低，性能差需转发）——只有rabbitMQ使用服务端转发

生产分区分配策略（创建topic时需要指定分区数就是为了这个，如果可以修改就可能会乱）
* 轮训：默认该策略，但是无法保证写入有序。 
* hash key：保证有序，但是有可能会分区倾斜 
* 手动指定：发送消息指定


#### 消费者
消费方式
* pull：
客户端主动去服务端拉取数据，减少服务端维护数据的压力，但是有可能无数据导致空pull的浪费	 （主流方式） ———— 日志型
* push：
服务端主动推数据给客户端，消息的及时性会更好。但是需要维护各个客户端订阅分区，消费偏移等
* pop： ———— 业务型
提供get接口获取数据，消费成功后ack数据（服务端可以感知数据消费到哪里）
解决方案——像redis中的bpop是一样无数据进行阻塞，需要考虑超时时间，请求数量，最少数量

#### 消费组
当单个消费者消费的速度较慢 => 同时给多个消费者消费  =》 通过组的概念
要求保证有序、不重复消费（组内消费者消费哪个分区）、
* 协调者（在broker的一个模块）
1. 消费者和分区进行分配就需要有个模块进行处理（有多少分组，所有消费者，分区的信息）
2. 当分区/消费者的数量发生改变就需要重平衡（内部完成分配，再把分配关系同步给所有消费者）
3. 同时记录每个消费者组的消费进度

* 重平衡后分区的分配原则
1. 尽可能均匀的分配到每个消费者（轮询）
2. 重平衡后尽可能减少变动（一致性hash）
3. 可以灵活的制定分配关系（自定义）

* 消费失败
1. 拉取失败（根据重试错误跟不可重试错误分类——重复消费或向上抛错）
2. 业务处理失败（在业务代码做好重试逻辑+手动提交处理，如果一直失败则需要考虑死信队列，确保进度不阻塞且能保存异常数据）
3. 提交失败（事务回滚，重试逻辑+手动提交处理，死信队列）


### 各个消息队列对比
|   表头   |  rabbitMq  |        Kafka         |         RocketMq         |         pulser         |
|:------:|:----------:|:--------------------:|:------------------------:|:----------------------:|
| 应用层协议  | AMQP/HTTP  | Kafka protocl / HTTP | Rocketmq remoting / HTTP | pulsar protocl / HTTP  |
| 元数据存储  |   Mnesia   |      Zookeeper       |        NameServer        |       Zookeeper        |
|  数据过期  | queue和消息维度 |       时间及分区大小        |         时间、节点维度          |        时间、节点维度         |
|  数据删除  |  queue维度   |     分区segment维度      |       节点segment维度        |       分区ledger维度       |
| 客户端寻址  |     无      |  连接broker完成寻址（tcp）   |  连接NameServer完成寻址（tcp）   | 连接broker完成寻址（tcp和http） |
|  分区分配  |     无      |   轮训，按key hash，自定义   |      轮训，最小投递延迟，自定义       |       轮训，随机，自定义        |
|  消费模型  | pull，push  |         pull         |      pull，push，pop       |          pull          |
| 消费确认机制 |   消费进度保存   |        消费位点保存        |          消费位点保存          |         游标位点保存         |
|  消费确认  |   单条ack    |        批量ack         |          批量ack           |      单条ack，批量ack       |

 ddd |	rabbitMq|	Kafka	|RocketMq	|pulser|
:---:|:---: :---:|:---: |:---: | :---:  |:---:  | 
应用层协议	AMQP/HTTP	Kafka protocl / HTTP	Rocketmq remoting / HTTP	pulsar protocl / HTTP
元数据存储	Mnesia	Zookeeper	NameServer	Zookeeper
数据过期	queue和消息维度	 时间及分区大小	时间、节点维度	时间、节点维度
数据删除	queue维度	分区segment维度	节点segment维度	分区ledger维度
客户端寻址	无	连接broker完成寻址（tcp）	连接NameServer完成寻址（tcp）	连接broker完成寻址
（tcp和http）
分区分配	无	轮训，按key hash，自定义	轮训，最小投递延迟，自定义	轮训，随机，自定义
消费模型	pull，push	pull	pull，push，pop	pull
消费确认机制	消费进度保存	消费位点保存	消费位点保存	游标位点保存
消费确认	单条ack	批量ack	批量ack	单条ack，批量ack




#### 高性能及高可靠性
生产者
- 网络层面（底层）
  * 连接：生产者会跟broker建立连接并保持（避免每次都重新连接） 
  * 网络稳定性：由于tcp会丢包重传导致时间延长 
  * 网络延迟：避免跨区域之间导致传输耗时过大 
  * 带宽：避免带宽满了需要阻塞等待（生产者带宽，网络链路带宽，broker带宽） 
  * 加密：避免在传输过程中被篡改等但会影响cpu性能
- SDK层面（应用层） 
  * 发送模式：发送即忘，同步发送，异步发送 
  * 批量发送：本地聚合批量发送 
  * 多tcp：避免单个tcp成为性能瓶颈 
  * 报错异常：需要捕获异常，记录报错的数据（有据可查）

broker
* 逻辑处理：数据重组，协议转换，java虚拟机调优
* 操作系统：pageCache刷屏策略，socket最大缓存区大小，fd数量
* 物理硬件:
  * cpu ：不是计算密集型,只要不满就够用
  * 网卡：只要不满就够用 
  * 内存：需要依赖大量内存 
  * 硬盘：依赖大量写数据到磁盘

消费者
* 避免重平衡（1会暂停分区的消费，2.消费分区会进行重新分配） 
* 手动提交ack，避免重复消费及报错导致丢失，可批量ack提高新更难过 
* 避免跨区，跨地域的 消费


### 基础命令
|                        命令                        |                          内容                           |                                                                                                       json                                                                                                       |
|:------------------------------------------------:|:-----------------------------------------------------:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|
|                 get /controller                  | 获取kafka  controller在哪个broker上（负责broker与metadata交互的节点） |                                                                             {"version":1,"brokerid":100,"timestamp":"1683685083226"}                                                                             |
|               get /brokers/ids/100               |                    获取broker xxx的信息                    | {"features":{},"listener_security_protocol_map":{"PLAINTEXT":"PLAINTEXT"},"endpoints":["PLAINTEXT://159.75.1.200:9093"],"jmx_port":-1,"port":9093,"host":"159.75.1.200","version":5,"timestamp":"1683685083110"} |
|          get /brokers/topics/hume_test           |                 获取topic hume_test元信息                  |                                              {"partitions":{"0":[100]},"topic_id":"T9Jn8YAFTr61tXSp9yV6FA","adding_replicas":{},"removing_replicas":{},"version":3}                                              |
| get /brokers/topics/hume_test/partitions/0/state |                获取topic hume_test分区0的信息                |                                                                   {"controller_epoch":2,"leader":100,"version":1,"leader_epoch":0,"isr":[100]}                                                                   |